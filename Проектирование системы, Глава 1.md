### Что такое системное проектирование?

**Системное проектирование** — это процесс определения архитектуры, интерфейсов и данных для системы, удовлетворяющей конкретным требованиям. Оно требует системного подхода к построению и проектированию систем. 

**Почему системное проектирование так важно?**

Системное проектирование помогает нам определить решение, которое соответствует бизнес-требованиям. Это одно из самых ранних решений, которые мы можем принять при построении системы. Оно также упрощает осмысление и управление архитектурными изменениями по мере развития системы.

---

### IP-адрес (Internet Protocol) ###

**IP-адрес** — это уникальный адрес, который идентифицирует устройство в интернете или локальной сети. IP означает «Межсетевой протокол» (Internet Protocol) — набор правил, определяющих формат данных, отправляемых через интернет или локальную сеть.

По сути, IP-адреса являются идентификаторами, которые позволяют передавать информацию между устройствами в сети. Они содержат информацию о местоположении и делают устройства доступными для связи. 
#### Версии ####

* IPv4
Оригинальный протокол IPv4 использует 32-битную числовую точечно-десятичную нотацию, которая позволяет иметь только около 4 миллиардов IP-адресов. Изначально этого было более чем достаточно, но по мере роста распространения интернета нам потребовалось что-то лучшее.
	*   **Пример:** ==`102.22.192.181` ==

* IPv6
IPv6 — это новый протокол, представленный в 1998 году. Развертывание началось в середине 2000-х, и поскольку число пользователей интернета выросло экспоненциально, оно все еще продолжается.
Этот новый протокол использует 128-битную буквенно-цифровую шестнадцатеричную нотацию. Это означает, что IPv6 может предоставить около ~340e+36 IP-адресов. 
	* ***Пример:** ==`2001:0db8:85a3:0000:0000:8a2e:0370:7334` ==

#### Типы  ####

* **Публичный (Public)**
Публичный IP-адрес — это адрес, связанный со всей вашей сетью. При этом типе IP-адреса каждое из подключенных устройств имеет один и тот же IP-адрес.

* **Приватный (Private)**
Приватный IP-адрес — это уникальный IP-номер, назначаемый каждому устройству, которое подключается к вашей интернет-сети, включая такие устройства, как компьютеры, планшеты и смартфоны, используемые в вашем доме.

* **Статический (Static)**
Статический IP-адрес не меняется и создается вручную, в отличие от назначенного автоматически. Эти адреса обычно дороже, но более надежны.

* **Динамический (Dynamic)**
Динамический IP-адрес время от времени меняется и не всегда одинаков. Он назначается сервером протокола динамической конфигурации узла (DHCP). Динамические IP-адреса являются наиболее распространенным типом адресов интернет-протокола. Они дешевле в развертывании и позволяют при необходимости повторно использовать IP-адреса в сети.

---

### Модель OSI ###

**Модель OSI** — это логическая и концептуальная модель, которая определяет сетевое взаимодействие, используемое системами, открытыми для соединения и связи с другими системами. Модель взаимодействия открытых систем (OSI) также определяет логическую сеть и эффективно описывает передачу компьютерных пакетов с использованием различных уровней протоколов.

Модель OSI можно рассматривать как универсальный язык для компьютерных сетей. Она основана на концепции разделения системы связи на семь абстрактных уровней, каждый из которых надстроен над предыдущим.

**Почему важна модель OSI?**

Модель взаимодействия открытых систем (OSI) определила общую терминологию, используемую в сетевых обсуждениях и документации. Это позволяет нам разобрать очень сложный процесс связи и оценить его компоненты.

**Она может помочь нам сделать:**
*   Облегчить поиск и устранение неисправностей и помочь выявить угрозы во всем стеке.
*   Стимулировать производителей оборудования создавать сетевые продукты, которые могут взаимодействовать друг с другом по сети.
*   Необходима для развития мышления, ориентированного в первую очередь на безопасность.
*   Разделяет сложную функцию на более простые компоненты.

#### Уровни ####

Семь уровней абстракции модели OSI можно определить следующим образом, сверху вниз:

1.  **Прикладной уровень (Application)**
    Это единственный уровень, который напрямую взаимодействует с данными от пользователя. Такие программные приложения, как веб-браузеры и почтовые клиенты, полагаются на прикладной уровень для инициирования связи. Протоколы прикладного уровня включают HTTP, а также SMTP.

2.  **Уровень представления (Presentation)**
    Уровень представления также называют уровнем трансляции (Translation). Данные из прикладного уровня извлекаются здесь и обрабатываются в соответствии с требуемым форматом для передачи по сети. Функциями уровня представления являются трансляция, шифрование/дешифрование и сжатие.

3.  **Сеансовый уровень (Session)**
    Это уровень, ответственный за открытие и закрытие связи между двумя устройствами. Время между открытием и закрытием связи называется сеансом. Сеансовый уровень гарантирует, что сеанс остается открытым достаточно долго для передачи всех обмениваемых данных, а затем немедленно закрывает сеанс, чтобы избежать нерационального использования ресурсов. Сеансовый уровень также синхронизирует передачу данных с контрольными точками.

4.  **Транспортный уровень (Transport)**
    Транспортный уровень (также известный как уровень 4) отвечает за сквозную (end-to-end) связь между двумя устройствами. Это включает в себя взятие данных от сеансового уровня и разбиение их на фрагменты, называемые сегментами, перед отправкой на сетевой уровень (уровень 3). Он также отвечает за повторную сборку сегментов на принимающем устройстве в данные, которые может потреблять сеансовый уровень.

5.  **Сетевой уровень (Network)**
    Сетевой уровень отвечает за обеспечение передачи данных между двумя разными сетями. Сетевой уровень разбивает сегменты с транспортного уровня на более мелкие единицы, называемые пакетами, на устройстве-отправителе и собирает эти пакеты на принимающем устройстве. Сетевой уровень также находит лучший физический путь для достижения данных пункта назначения; это известно как маршрутизация. Если два взаимодействующих устройства находятся в одной сети, то сетевой уровень не требуется.

6.  **Канальный уровень (Data Link)**
    Канальный уровень очень похож на сетевой уровень, за исключением того, что канальный уровень обеспечивает передачу данных между двумя устройствами в одной сети. Канальный уровень принимает пакеты от сетевого уровня и разбивает их на более мелкие части, называемые кадрами.

7.  **Физический уровень (Physical)**
    Этот уровень включает физическое оборудование, участвующее в передаче данных, такое как кабели и коммутаторы. Это также уровень, на котором данные преобразуются в битовый поток — строку из единиц и нулей. Физический уровень обоих устройств также должен согласовывать соглашение о сигналах, чтобы единицы могли быть distinguished от нулей на обоих устройствах.

---

### TCP и UDP ###

* **TCP (Transmission Control Protocol)**
	TCP является соединением-ориентированным (connection-oriented), что означает, что после установления соединения данные могут передаваться в обоих направлениях. TCP имеет встроенные системы для проверки ошибок и гарантии доставки данных в том порядке, в котором они были отправлены, что делает его идеальным протоколом для передачи такой информации, как статические изображения, файлы данных и веб-страницы.

* **UDP (User Datagram Protocol)** 
	UDP — это более простой, не требующий установления соединения (connectionless) интернет-протокол, в котором не требуются услуги проверки ошибок и восстановления. При использовании UDP нет издержек на установление соединения, поддержание соединения или завершение соединения. Данные continuously отправляются получателю, независимо от того, получает он их или нет.

Он в значительной степени предпочтителен для коммуникаций в реальном времени, таких как широковещательная (broadcast) или многоадресная (multicast) сетевая передача. Мы должны использовать UDP вместо TCP, когда нам нужна минимальная задержка, а запоздалые данные хуже, чем потеря данных.

#### TCP против UDP ####

TCP — это протокол с установлением соединения, тогда как UDP — это протокол без установления соединения. Ключевое различие между TCP и UDP — скорость, так как TCP сравнительно медленнее, чем UDP. В целом, UDP — это гораздо более быстрый, простой и эффективный протокол, однако повторная передача потерянных пакетов данных возможна только с TCP.

TCP обеспечивает упорядоченную доставку данных от пользователя к серверу (и наоборот), тогда как UDP не предназначен для сквозной связи и не проверяет готовность получателя.

| Функция                      | TCP                                            | UDP                                               |
| :--------------------------- | :--------------------------------------------- | :------------------------------------------------ |
| **Соединение**               | Требует установленного соединения              | Протокол без установления соединения              |
| **Гарантированная доставка** | Может гарантировать доставку данных            | Не может гарантировать доставку данных            |
| **Повторная передача**       | Повторная передача потерянных пакетов возможна | Повторная передача потерянных пакетов отсутствует |
| **Скорость**                 | Медленнее, чем UDP                             | Быстрее, чем TCP                                  |
| **Широковещание**            | Не поддерживает широковещание                  | Поддерживает широковещание                        |
| **Примеры использования**    | HTTPS, HTTP, SMTP, POP, FTP и т.д.             | Видеостриминг, DNS, VoIP и т.д.                   |

---

### Domain Name System (DNS) ###

Ранее мы узнали об [[#IP-адрес (Internet Protocol)]], которые позволяют каждой машине подключаться к другим машинам. Но, как мы знаем, людям удобнее работать с именами, чем с числами. Легче запомнить имя типа ==`google.com`==, чем что-то вроде ==`122.250.192.232`==.

Это подводит нас к **Domain Name System (DNS)** — иерархической и децентрализованной системе имен, используемой для преобразования удобочитаемых доменных имен в IP-адреса.

#### Как работает DNS ####

Поиск в DNS (DNS lookup) включает следующие восемь шагов:
1.  Клиент вводит ==`example.com`== в веб-браузер, запрос отправляется в интернет и принимается DNS-резолвером.
2.  Резолвер затем рекурсивно запрашивает корневой DNS-сервер имен.
3.  Корневой сервер отвечает резолверу адресом сервера имен домена верхнего уровня (TLD).
4.  Резолвер затем делает запрос к TLD-серверу ==`.com`==.
5.  TLD-сервер затем отвечает IP-адресом сервера имен домена ==`example.com`==.
6.  Наконец, рекурсивный резолвер отправляет запрос на сервер имен домена.
7.  IP-адрес для `example.com` затем возвращается резолверу от сервера имен.
8.  DNS-резолвер затем отвечает веб-браузеру с IP-адресом изначально запрошенного домена.

После того как IP-адрес разрешен, клиент должен иметь возможность запрашивать контент с разрешенного IP-адреса. Например, разрешенный IP-адрес может вернуть веб-страницу для отображения в браузере.

#### Типы серверов ####

* **DNS-резолвер (DNS Resolver)**
	DNS-резолвер (также известный как рекурсивный резолвер) — это первая остановка в DNS-запросе. Рекурсивный резолвер действует как посредник между клиентом и DNS-сервером имен. Получив DNS-запрос от веб-клиента, рекурсивный резолвер либо ответит кэшированными данными, либо отправит запрос на корневой сервер имен, затем другой запрос на TLD-сервер имен и, наконец, последний запрос на авторитетный сервер имен. Получив ответ от авторитетного сервера имен, содержащий запрошенный IP-адрес, рекурсивный резолвер затем отправляет ответ клиенту.

* **Корневой DNS-сервер (DNS root server)**
	Корневой сервер принимает запрос рекурсивного резолвера, который включает доменное имя, и корневой сервер имен отвечает, направляя рекурсивный резолвер на TLD-сервер имен на основе расширения этого домена (`.com`, `.net`, `.org` и т.д.). Корневыми серверами имен руководит некоммерческая организация под названием Корпорация по управлению доменными именами и IP-адресами (ICANN).

Существует 13 *типов* корневых серверов имен, но есть несколько копий каждого из них по всему миру, которые используют маршрутизацию Anycast для обеспечения быстрых ответов.

* **TLD-сервер имен (TLD nameserver)**
	TLD-сервер имен хранит информацию обо всех доменных именах, которые имеют общее доменное расширение, такое как `.com`, `.net` или что бы то ни было после последней точки в URL-адресе.

Управление TLD-серверами имен осуществляется Управлением по присвоению номеров в интернете (IANA), которое является подразделением ICANN. IANA разделяет TLD-серверы на две основные группы:
*   **Общие домены верхнего уровня (gTLD):** Это такие домены, как ==`.com`, `.org`, `.net`, `.edu` и `.gov`==.
*   **Национальные домены верхнего уровня (ccTLD):** Сюда входят любые домены, специфичные для страны или штата. Примеры: ==`.uk`, `.us`, `.ru` и `.jp`==.

* **Авторитетный DNS-сервер (Authoritative DNS server)**
	Авторитетный сервер имен обычно является последним шагом для резолвера в поиске IP-адреса. Авторитетный сервер имен содержит информацию, относящуюся к доменному имени, которое он обслуживает (например, ==`google.com`==), и он может предоставить рекурсивному резолверу IP-адрес этого сервера, найденный в DNS-записи A, или, если домен имеет запись CNAME (псевдоним), он предоставит рекурсивному резолверу псевдоним домена, и в этот момент рекурсивному резолверу придется выполнить совершенно новый DNS-поиск, чтобы получить запись с авторитетного сервера имен (часто запись A, содержащую IP-адрес). Если он не может найти домен, возвращается сообщение NXDOMAIN.

#### Типы запросов ####

В DNS-системе существует три типа запросов:

* **Рекурсивный (Recursive)**
	При рекурсивном запросе DNS-клиент требует, чтобы DNS-сервер (обычно DNS-рекурсивный резолвер) ответил клиенту либо запрошенной ресурсной записью, либо сообщением об ошибке, если резолвер не может найти запись.

* **Итеративный (Iterative)**
	При итеративном запросе DNS-клиент предоставляет имя хоста, и DNS-резолвер возвращает лучший ответ, который он может. Если DNS-резолвер имеет соответствующие DNS-записи в своем кэше, он возвращает их. Если нет, он отсылает DNS-клиента к корневому серверу или другому авторитетному серверу имен, который находится ближе всего к требуемой DNS-зоне. Затем DNS-клиент должен повторить запрос напрямую к DNS-серверу, на который его перенаправили.

* **Нерекурсивный (Non-recursive)**
	Нерекурсивный запрос — это запрос, в котором DNS-резолвер уже знает ответ. Он либо немедленно возвращает DNS-запись, потому что уже хранит ее в локальном кэше, либо запрашивает DNS-сервер имен, который является авторитетным для этой записи, то есть он определенно содержит правильный IP-адрес для этого имени хоста. В обоих случаях нет необходимости в дополнительных раундах запросов (как в рекурсивных или итеративных запросах). Скорее, ответ немедленно возвращается клиенту.

#### Типы записей ####

**DNS-записи** (также известные как файлы зон) — это инструкции, которые находятся на авторитетных DNS-серверах и предоставляют информацию о домене, включая то, какой IP-адрес связан с этим доменом и как обрабатывать запросы для этого домена.

Эти записи состоят из серии текстовых файлов, написанных на так называемом DNS-синтаксисе. DNS-синтаксис — это просто строка символов, используемая в качестве команд, которые говорят DNS-серверу, что делать. Все DNS-записи также имеют «TTL» (время жизни), который указывает, как часто DNS-сервер будет обновлять эту запись.

Существует больше типов записей, но пока давайте рассмотрим некоторые из наиболее часто используемых:

*   **A (Адресная запись):** Это запись, которая содержит IP-адрес домена.
*   **AAAA (Запись адреса IPv6):** Запись, которая содержит IPv6-адрес для домена (в отличие от записей A, которые хранят IPv4-адрес).
*   **CNAME (Каноническая запись имени):** Перенаправляет один домен или поддомен на другой домен, НЕ предоставляет IP-адрес.
*   **MX (Запись почтового обменника):** Направляет почту на почтовый сервер.
*   **TXT (Текстовая запись):** Эта запись позволяет администратору хранить текстовые заметки в записи. Эти записи часто используются для безопасности электронной почты.
*   **NS (Записи сервера имен):** Хранит сервер имен для DNS-записи.
*   **SOA (Начало полномочий):** Хранит административную информацию о домене.
*   **SRV (Запись местоположения службы):** Указывает порт для определенных служб.
*   **PTR (Запись указателя обратного просмотра):** Предоставляет доменное имя при обратном поиске.
*   **CERT (Запись сертификата):** Хранит сертификаты открытых ключей.

#### Поддомены ####

**Поддомен** — это дополнительная часть нашего основного доменного имени. Он обычно используется для логического разделения веб-сайта на разделы. Мы можем создать несколько поддоменов или дочерних доменов на основном домене.

#### DNS-зоны ####

**DNS-зона** — это отдельная часть пространства имен домена, которая делегирована юридическому лицу, такому как человек, организация или компания, которое отвечает за обслуживание DNS-зоны. DNS-зона также является административной функцией, позволяющей осуществлять детальный контроль над компонентами DNS, такими как авторитетные серверы имен.

#### DNS-кэширование ####

**DNS-кэш** (иногда называемый кэшем DNS-резолвера) — это временная база данных, поддерживаемая операционной системой компьютера, которая содержит записи обо всех недавних посещениях и попытках посещения веб-сайтов и других интернет-доменов. 

Система доменных имен реализует **время жизни (TTL)** для каждой DNS-записи. TTL указывает количество секунд, в течение которых запись может кэшироваться DNS-клиентом или сервером. Когда запись сохраняется в кэше, значение TTL, которое пришло с ней, также сохраняется. Сервер продолжает обновлять TTL записи, хранящейся в кэше, отсчитывая каждую секунду. Когда он достигает нуля, запись удаляется или очищается из кэша. В этот момент, если поступает запрос на эту запись, DNS-сервер должен начать процесс разрешения.

#### Обратный DNS (Reverse DNS) ####

**Обратный DNS-поиск** — это DNS-запрос для доменного имени, связанного с данным IP-адресом. Это достигает противоположного тому, что делает более часто используемый прямой DNS-поиск, в котором запрашивается DNS-система для возврата IP-адреса. Процесс обратного разрешения IP-адреса использует PTR-записи. Если сервер не имеет PTR-записи, он не может разрешить обратный поиск.

Обратный поиск обычно используется почтовыми серверами. Почтовые серверы проверяют, поступило ли электронное письмо с действительного сервера, прежде чем принять его в свою сеть. Многие почтовые серверы будут отклонять сообщения с любого сервера, который не поддерживает обратный поиск или с сервера, который вряд ли является законным.

>Обратный DNS-поиск не является повсеместно принятым, поскольку он не критичен для нормального функционирования интернета.*

---

### Балансировка нагрузки (Load Balancing) ###

**Балансировка нагрузки** позволяет нам распределять входящий сетевой трафик между несколькими ресурсами, обеспечивая высокую доступность и надежность, отправляя запросы только к ресурсам, которые находятся в сети. Это обеспечивает гибкость добавления или изъятия ресурсов по мере спроса.

Для дополнительной масштабируемости и избыточности мы можем попытаться балансировать нагрузку на каждом уровне нашей системы.

#### Зачем это нужно? ####

Современные веб-сайты с высоким трафиком должны обслуживать сотни тысяч, если не миллионы, одновременных запросов от пользователей или клиентов. Чтобы масштабироваться для удовлетворения этих высоких объемов рентабельно, современные best practice вычислений, как правило, требуют добавления большего количества серверов.

Балансировщик нагрузки может располагаться перед серверами и маршрутизировать клиентские запросы по всем серверам, способным выполнить эти запросы, таким образом, чтобы максимизировать скорость и использование емкости. Это гарантирует, что ни один сервер не будет перегружен, что может ухудшить производительность. Если один сервер выходит из строя, балансировщик нагрузки перенаправляет трафик на оставшиеся работающие серверы. Когда новый сервер добавляется в группу серверов, балансировщик нагрузки автоматически начинает отправлять ему запросы.

#### Распределение рабочей нагрузки (Workload distribution) ####

Это основная функциональность, предоставляемая балансировщиком нагрузки, и имеет несколько распространенных вариантов:
*   **На основе хоста (Host-based):** Распределяет запросы на основе запрашиваемого имени хоста.
*   **На основе пути (Path-based):** Использует весь URL для распределения запросов, а не только имя хоста.
*   **На основе содержимого (Content-based):** Проверяет содержимое сообщения запроса. Это позволяет распределять на основе контента, такого как значение параметра.

#### Уровни

Вообще говоря, балансировщики нагрузки работают на одном из двух уровней:

* **Сетевой уровень (Network layer)**
	Это балансировщик нагрузки, который работает на транспортном уровне сети, также известном как уровень 4. Он выполняет маршрутизацию на основе сетевой информации, такой как IP-адреса, и не может выполнять маршрутизацию на основе содержимого. Часто это выделенные аппаратные устройства, которые могут работать на высокой скорости.

* **Уровень приложений (Application layer)**
	Это балансировщик нагрузки, который работает на уровне приложений, также известном как уровень 7. Балансировщики нагрузки могут читать запросы полностью и выполнять маршрутизацию на основе содержимого. Это позволяет управлять нагрузкой на основе полного понимания трафика.

#### Типы

Давайте посмотрим на различные типы балансировщиков нагрузки:

* **Программные (Software)**
	Программные балансировщики нагрузки обычно легче развернуть, чем аппаратные версии. Они также, как правило, более рентабельны и гибки, и они используются в сочетании со средами разработки программного обеспечения. Программный подход дает нам гибкость настройки балансировщика нагрузки в соответствии с конкретными потребностями нашей среды. Увеличение гибкости может потребовать больше работы по настройке балансировщика нагрузки. 

* **Аппаратные (Hardware)**
	Как следует из названия, аппаратный балансировщик нагрузки relies на физическом, локальном оборудовании для распределения трафика приложений и сети. Эти устройства могут обрабатывать большой объем трафика, но часто имеют высокую цену и довольно ограничены с точки зрения гибкости.
	
	Аппаратные балансировщики нагрузки включают проприетарное firmware, которое требует обслуживания и обновлений по мере выхода новых версий и исправлений безопасности.

* **DNS-балансировка нагрузки (DNS)**
	DNS-балансировка нагрузки — это практика настройки домена в системе доменных имен (DNS) таким образом, что клиентские запросы к домену распределяются по группе серверных машин.
	
	К сожалению, DNS-балансировка нагрузки имеет присущие ей проблемы, ограничивающие ее надежность и эффективность. Наиболее значительно, DNS не проверяет сбои серверов и сети или ошибки. Он всегда возвращает один и тот же набор IP-адресов для домена, даже если серверы не работают или недоступны.

#### Алгоритмы маршрутизации (Routing Algorithms)

Теперь давайте обсудим commonly используемые алгоритмы маршрутизации:

*   **Циклический (Round-robin):** Запросы распределяются по серверам приложений по очереди.
*   **Взвешенный циклический (Weighted Round-robin):** Развивает простую технику Round-robin для учета различных характеристик серверов, таких как вычислительная мощность и пропускная способность обработки трафика, с использованием весов, которые могут быть назначены администратором через DNS-записи.
*   **Наименьшее соединение (Least Connections):** Новый запрос отправляется на сервер с наименьшим текущим количеством соединений с клиентами. Относительная вычислительная мощность каждого сервера учитывается при определении того, у кого меньше всего соединений.
*   **Наименьшее время отклика (Least Response Time):** Отправляет запросы на сервер, выбранный по формуле, которая сочетает в себе самое быстрое время отклика и наименьшее количество активных соединений.
*   **Наименьшая пропускная способность (Least Bandwidth):** Этот метод измеряет трафик в мегабитах в секунду (Мбит/с), отправляя клиентские запросы на сервер с наименьшим трафиком в Мбит/с.
*   **Хеширование (Hashing):** Распределяет запросы на основе ключа, который мы определяем, такого как IP-адрес клиента или URL запроса.

#### Преимущества

Балансировка нагрузки также играет ключевую роль в предотвращении простоев, другие преимущества балансировки нагрузки включают следующее:
*   Масштабируемость (Scalability)
*   Избыточность (Redundancy)
*   Гибкость (Flexibility)
*   Эффективность (Efficiency)

#### Избыточные балансировщики нагрузки (Redundant load balancers)

Как вы, должно быть, уже догадались, сам балансировщик нагрузки может быть единой точкой отказа. Чтобы преодолеть это, второй или N-ное количество балансировщиков нагрузки может быть использовано в кластерном режиме.

И, если есть обнаружение сбоя и активный балансировщик нагрузки выходит из строя, другой пассивный балансировщик нагрузки может взять на себя управление, что сделает нашу систему более отказоустойчивой.

#### Функции

Вот некоторые commonly желаемые функции балансировщиков нагрузки:

*   **Автомасштабирование (Autoscaling):** Запуск и остановка ресурсов в ответ на условия спроса.
*   **Закрепленные сессии (Sticky sessions):** Возможность назначать одного и того же пользователя или устройство одному и тому же ресурсу для поддержания состояния сеанса на ресурсе.
*   **Проверки здоровья (Healthchecks):** Возможность определить, что ресурс не работает или работает плохо, чтобы удалить ресурс из пула балансировки нагрузки.
*   **Постоянные соединения (Persistence connections):** Позволяют серверу открывать постоянное соединение с клиентом, такое как WebSocket.
*   **Шифрование (Encryption):** Обработка зашифрованных соединений, таких как TLS и SSL.
*   **Сертификаты (Certificates):** Представление сертификатов клиенту и аутентификация клиентских сертификатов.
*   **Сжатие (Compression):** Сжатие ответов.
*   **Кэширование (Caching):** Балансировщик нагрузки уровня приложений может предлагать возможность кэшировать ответы.
*   **Логирование (Logging):** Логирование метаданных запроса и ответа может служить важным аудиторским следом или источником для аналитики.
*   **Трассировка запросов (Request tracing):** Назначение каждому запросу уникального идентификатора для целей логирования, мониторинга и устранения неполадок.
*   **Перенаправления (Redirects):** Возможность перенаправить входящий запрос на основе таких факторов, как запрашиваемый путь.
*   **Фиксированный ответ (Fixed response):** Возврат статического ответа на запрос, такого как сообщение об ошибке.

#### Примеры

Ниже приведены некоторые из решений для балансировки нагрузки, обычно используемых в отрасли:
*   Amazon Elastic Load Balancing
*   Azure Load Balancing
*   GCP Load Balancing
*   DigitalOcean Load Balancer
*   Nginx
*   HAProxy

---

### Кластеризация (Clustering) ###

На высоком уровне **компьютерный кластер** — это группа из двух или более компьютеров или узлов, которые работают параллельно для достижения общей цели. Это позволяет распределять рабочие нагрузки, состоящие из большого количества индивидуальных, распараллеливаемых задач, между узлами в кластере. В результате эти задачи могут использовать объединенную память и вычислительную мощность каждого компьютера для повышения общей производительности.

Чтобы построить компьютерный кластер, отдельные узлы должны быть подключены к сети, чтобы обеспечить связь между узлами. Затем программное обеспечение может быть использовано для соединения узлов вместе и формирования кластера. Он может иметь общее устройство хранения данных и/или локальное хранилище на каждом узле.

Обычно по крайней мере один узел назначается ведущим узлом (leader node) и действует как точка входа в кластер. Ведущий узел может быть responsible за делегирование входящей работы другим узлам и, при необходимости, агрегацию результатов и возврат ответа пользователю.

В идеале кластер функционирует так, как если бы он был единой системой. Пользователь, получающий доступ к кластеру, не должен знать, является ли система кластером или отдельной машиной. Кроме того, кластер должен быть спроектирован так, чтобы минимизировать задержку и предотвратить узкие места в связи между узлами.

#### Типы

Компьютерные кластеры обычно можно разделить на три типа:
*   Высокодоступные или отказоустойчивые (Highly available or fail-over)
*   Балансировки нагрузки (Load balancing)
*   Высокопроизводительные вычисления (High-performance computing)

#### Конфигурации

Две наиболее часто используемые конфигурации кластеризации высокой доступности (HA) — это активный-активный (active-active) и активный-пассивный (active-passive).

* **Активный-Активный (Active-Active)**
	Активно-активный кластер обычно состоит по крайней мере из двух узлов, оба из которых одновременно активно выполняют один и тот же вид службы. Основная цель активно-активного кластера — достижение балансировки нагрузки. Балансировщик нагрузки распределяет рабочие нагрузки по всем узлам, чтобы предотвратить перегрузку любого отдельного узла. Поскольку доступно больше узлов для обслуживания, также произойдет улучшение пропускной способности и времени отклика.

* **Активный-Пассивный (Active-Passive)**
	Как и конфигурация активно-активного кластера, активно-пассивный кластер также состоит по крайней мере из двух узлов. Однако, как следует из названия активно-пассивный, не все узлы будут активными. Например, в случае двух узлов, если первый узел уже активен, то второй узел должен быть пассивным или в режиме ожидания (standby).

#### Преимущества

Четыре ключевых преимущества кластерных вычислений заключаются в следующем:
*   Высокая доступность (High availability)
*   Масштабируемость (Scalability)
*   Производительность (Performance)
*   Рентабельность (Cost-effective)

#### Балансировка нагрузки против Кластеризации

Балансировка нагрузки имеет некоторые общие черты с кластеризацией, но это разные процессы. Кластеризация обеспечивает избыточность и повышает емкость и доступность. Серверы в кластере знают друг о друге и работают вместе для достижения общей цели. Но при балансировке нагрузки серверы не знают друг о друге. Вместо этого они реагируют на запросы, которые получают от балансировщика нагрузки.

Мы можем использовать балансировку нагрузки в сочетании с кластеризацией, но она также применима в случаях, involving независимых серверов, которые разделяют общую цель, например, для запуска веб-сайта, бизнес-приложения, веб-сервиса или какого-либо другого ИТ-ресурса.

#### Проблемы (Challenges)

Самая очевидная проблема, которую представляет кластеризация, — это возросшая сложность установки и обслуживания. Операционная система, приложение и его зависимости должны быть установлены и обновлены на каждом узле.

Это становится еще более сложным, если узлы в кластере не являются однородными. Использование ресурсов для каждого узла также должно тщательно контролироваться, а логи должны агрегироваться, чтобы гарантировать, что программное обеспечение работает правильно.

Кроме того, управление хранилищем становится более трудным, общее устройство хранения данных должно предотвращать перезапись узлами друг друга, а распределенные хранилища данных должны поддерживаться в синхронизированном состоянии.

#### Примеры

Кластеризация обычно используется в отрасли, и часто многие технологии предлагают какой-то режим кластеризации. Например:
*   Контейнеры (например, Kubernetes, Amazon ECS)
*   Базы данных (например, Cassandra, MongoDB)
*   Кэш (например, Redis)

---

### Кэширование (Caching) ###

> "В компьютерных науках есть только две сложные вещи: инвалидация кэша и именование вещей." - Фил Карлтон

Основная цель **кэша** — увеличить производительность извлечения данных за счет сокращения необходимости доступа к более медленному нижележащему уровню хранения. Обменивая емкость на скорость, кэш обычно хранит подмножество данных временно, в отличие от баз данных, чьи данные обычно полны и долговечны.

Кэши используют преимущество принципа локальности ссылок: «недавно запрошенные данные, вероятно, будут запрошены снова».

#### Кэширование и Память

Как и память компьютера, кэш — это компактная, быстродействующая память, которая хранит данные в иерархии уровней, начиная с уровня один и progressing оттуда последовательно. Они обозначаются как L1, L2, L3 и так далее. Кэш также записывается, если запрашивается, например, когда произошло обновление и новый контент needs to be сохранен в кэше, заменяя более старый контент, который был сохранен.

Независимо от того, читается кэш или записывается, это делается по одному блоку за раз. Каждый блок также имеет тег, который включает местоположение, где данные были сохранены в кэше. Когда данные запрашиваются из кэша, происходит поиск по тегам, чтобы найти конкретный контент, который нужен на уровне один (L1) памяти. Если правильные данные не найдены, проводятся дополнительные поиски в L2.

Если данные не найдены там, поиск продолжается в L3, затем L4 и так далее, пока они не будут найдены, затем они считываются и загружаются. Если данные вообще не найдены в кэше, то они записываются в него для быстрого извлечения в следующий раз.

#### Кэш-попадание и Кэш-промах (Cache hit and Cache miss)

**Кэш-попадание (Cache hit)**
Кэш-попадание описывает ситуацию, когда контент успешно обслуживается из кэша. Теги быстро ищутся в памяти, и когда данные найдены и считаны, это считается кэш-попаданием.

**Холодный, теплый и горячий кэш (Cold, Warm, and Hot Caches)**
Кэш-попадание также можно описать как холодное, теплое или горячее. В каждом из них описывается скорость, с которой данные считываются.

*   **Горячий кэш (Hot cache)** — это случай, когда данные считываются из памяти с максимально возможной скоростью. Это происходит, когда данные извлекаются из L1.
*   **Холодный кэш (Cold cache)** — это самая медленная возможная скорость для считывания данных, однако это все равно успех, поэтому это все равно считается кэш-попаданием. Данные просто найдены ниже в иерархии памяти, например, в L3 или ниже.
*   **Теплый кэш (Warm cache)** используется для описания данных, которые найдены в L2 или L3. Он не такой быстрый, как горячий кэш, но все же быстрее, чем холодный кэш. Вообще, вызов кэша теплым используется для выражения, что он медленнее и ближе к холодному кэшу, чем к горячему.

**Кэш-промах (Cache miss)**
Кэш-промах относится к случаю, когда память обыскивается, и данные не найдены. Когда это происходит, контент передается и записывается в кэш.

#### Инвалидация кэша (Cache Invalidation)

**Инвалидация кэша** — это процесс, в котором компьютерная система объявляет записи кэша недействительными и удаляет или заменяет их. Если данные изменяются, они должны быть инвалидированы в кэше, если нет, это может вызвать несогласованное поведение приложения. Существует три вида систем кэширования:

**Сквозной кэш (Write-through cache)**
Данные записываются в кэш и в соответствующую базу данных одновременно.
*   **Плюс:** Быстрое извлечение, полная согласованность данных между кэшем и хранилищем.
*   **Минус:** Высокая задержка для операций записи.

**Обходной кэш (Write-around cache)**
Запись идет напрямую в базу данных или постоянное хранилище, минуя кэш.
*   **Плюс:** Это может уменьшить задержку.
*   **Минус:** Это увеличивает кэш-промахи, потому что системе кэширования приходится считывать информацию из базы данных в случае кэш-промаха. В результате это может привести к более высокой задержке чтения в случае приложений, которые быстро записывают и повторно считывают информацию. Чтение происходит из более медленного бэкенд-хранилища и испытывает более высокую задержку.

**Обратный кэш (Write-back cache)**
Запись производится только на уровень кэширования, и запись подтверждается, как только запись в кэш завершается. Затем кэш асинхронно синхронизирует эту запись с базой данных.
*   **Плюс:** Это привело бы к снижению задержки и высокой пропускной способности для приложений с интенсивной записью.
*   **Минус:** Существует риск потери данных в случае сбоя уровня кэширования. Мы можем улучшить это, имея более одной реплики, подтверждающей запись в кэше.

#### Политики вытеснения (Eviction policies)

Ниже приведены некоторые из наиболее распространенных политик вытеснения кэша:

*   **First In First Out (FIFO):** Кэш вытесняет первый блок, к которому обращались первым, без учета того, как часто или сколько раз к нему обращались ранее.
*   **Last In First Out (LIFO):** Кэш вытесняет блок, к которому обращались последним, без учета того, как часто или сколько раз к нему обращались ранее.
*   **Least Recently Used (LRU):** Вытесняет наименее недавно использованные элементы первыми.
*   **Most Recently Used (MRU):** Вытесняет, в отличие от LRU, наиболее недавно использованные элементы первыми.
*   **Least Frequently Used (LFU):** Считает, как часто элемент требуется. Те, которые используются реже всего, вытесняются первыми.
*   **Случайная замена (Random Replacement - RR):** Случайным образом выбирает кандидата и вытесняет его, чтобы освободить место, когда это необходимо.

#### Распределенный кэш (Distributed Cache)

**Распределенный кэш** — это система, которая объединяет оперативную память (RAM) нескольких подключенных к сети компьютеров в единое хранилище данных в памяти, используемое как кэш данных для обеспечения быстрого доступа к данным. В то время как большинство кэшей традиционно находятся на одном физическом сервере или аппаратном компоненте, распределенный кэш может расти beyond ограничений памяти одного компьютера путем соединения нескольких компьютеров.

#### Глобальный кэш (Global Cache)

Как следует из названия, у нас будет один общий кэш, который будут использовать все узлы приложения. Когда запрошенные данные не найдены в глобальном кэше, это responsibility кэша — найти недостающий фрагмент данных из нижележащего хранилища данных.

#### Примеры использования

Кэширование может иметь множество реальных случаев использования, таких как:
*   Кэширование базы данных (Database Caching)
*   Сеть доставки контента (Content Delivery Network - CDN)
*   Кэширование DNS (DNS Caching)
*   Кэширование API (API Caching)

#### Когда не следует использовать кэширование?

Давайте также рассмотрим некоторые сценарии, в которых мы не должны использовать кэш:
*   Кэширование не помогает, когда доступ к кэшу занимает столько же времени, сколько и доступ к основному хранилищу данных.
*   Кэширование не работает так хорошо, когда запросы имеют низкую повторяемость (высокую случайность), потому что производительность кэширования comes from повторяющихся шаблонов доступа к памяти.
*   Кэширование не помогает, когда данные часто меняются, поскольку кэшированная версия рассинхронизируется, и к основному хранилищу данных приходится обращаться каждый раз.

Важно отметить, что кэш не следует использовать в качестве постоянного хранилища данных. Они почти всегда реализованы в энергозависимой памяти, потому что она быстрее, и поэтому их следует считать временными.

#### Преимущества

Ниже приведены некоторые преимущества кэширования:
*   Улучшает производительность
*   Уменьшает задержку
*   Снижает нагрузку на базу данных
*   Снижает сетевые затраты
*   Увеличивает пропускную способность чтения

#### Примеры

Вот некоторые commonly используемые технологии для кэширования:
*   Redis
*   Memcached
*   Amazon ElastiCache
*   Aerospike

---

### Сеть доставки контента (CDN) ###

**Сеть доставки контента (CDN)** — это географически распределенная группа серверов, которые работают вместе для обеспечения быстрой доставки интернет-контента. Как правило, статические файлы, такие как HTML/CSS/JS, фотографии и видео, обслуживаются из CDN.

#### Зачем использовать CDN?

Сеть доставки контента (CDN) увеличивает доступность и избыточность контента, одновременно снижая затраты на пропускную способность и повышая безопасность. Обслуживание контента из CDN может значительно улучшить производительность, поскольку пользователи получают контент из центров обработки данных, близких к ним, и наши серверы не должны обслуживать запросы, которые выполняет CDN.

#### Как работает CDN?

В CDN сервер-источник (origin server) содержит оригинальные версии контента, в то время как пограничные серверы (edge servers) многочисленны и распределены по различным местоположениям по всему миру.

Чтобы минимизировать расстояние между посетителями и сервером веб-сайта, CDN хранит кэшированную версию своего контента в нескольких географических местоположениях, известных как пограничные местоположения (edge locations). Каждое пограничное местоположение содержит несколько серверов кэширования, ответственных за доставку контента посетителям в непосредственной близости.

После того как статические ресурсы закэшированы на всех серверах CDN для определенного местоположения, все последующие запросы посетителей веб-сайта на статические ресурсы будут доставляться с этих пограничных серверов вместо источника, thus уменьшая нагрузку на источник и улучшая масштабируемость.

Например, когда кто-то в Великобритании запрашивает наш веб-сайт, который может быть размещен в США, ему будет обслуживаться из ближайшего пограничного местоположения, такого как лондонское пограничное местоположение. Это намного быстрее, чем если бы посетитель делал полный запрос к серверу-источнику, что увеличило бы задержку.

#### Типы

CDN обычно делятся на два типа:

* **Push CDN**
	Push CDN получают новый контент, когда на сервере происходят изменения. Мы берем на себя полную ответственность за предоставление контента, загружая его непосредственно в CDN и переписывая URL-адреса так, чтобы они указывали на CDN. Мы можем настроить, когда контент истекает и когда он обновляется. Контент загружается только тогда, когда он новый или изменен, минимизируя трафик, но максимизируя хранилище.
	
	Сайты с небольшим трафиком или сайты с контентом, который не часто обновляется, хорошо работают с Push CDN. Контент размещается в CDN один раз, вместо того чтобы перезатягиваться через регулярные промежутки времени.

* **Pull CDN**
	В ситуации с Pull CDN кэш обновляется на основе запроса. Когда клиент отправляет запрос, который требует извлечения статических ресурсов из CDN, если CDN их не имеет, то он извлечет недавно обновленные ресурсы с сервера-источника и заполнит свой кэш этими новыми ресурсами, а затем отправит этот новый закэшированный ресурс пользователю.
	
	В отличие от Push CDN, это требует меньше обслуживания, потому что обновления кэша на узлах CDN выполняются на основе запросов от клиента к серверу-источнику. Сайты с большим трафиком хорошо работают с Pull CDN, поскольку трафик распределяется более равномерно, и только недавно запрошенный контент остается в CDN.

#### Недостатки

Как мы все знаем, хорошие вещи сопровождаются дополнительными затратами, поэтому давайте обсудим некоторые недостатки CDN:
*   **Дополнительные расходы:** Использование CDN может быть дорогим, особенно для сервисов с высоким трафиком.
*   **Ограничения:** Некоторые организации и страны блокируют домены или IP-адреса популярных CDN.
*   **Местоположение:** Если большинство нашей аудитории находится в стране, где у CDN нет серверов, данные нашего веб-сайта, возможно, должны будут пройти большее расстояние, чем без использования какого-либо CDN.

#### Примеры

Вот некоторые широко используемые CDN:
*   Amazon CloudFront
*   Google Cloud CDN
*   Cloudflare CDN
*   Fastly

---

### Прокси (Proxy) ###

**Прокси-сервер** — это промежуточное аппаратное/программное обеспечение, находящееся между клиентом и внутренним сервером. Он получает запросы от клиентов и передает их на серверы-источники. Обычно прокси используются для фильтрации запросов, логирования запросов или иногда преобразования запросов (путем добавления/удаления заголовков, шифрования/дешифрования или сжатия).

#### Типы

Существует два типа прокси:

* **Прямой прокси (Forward Proxy)**
	Прямой прокси, часто называемый просто прокси, прокси-сервером или веб-прокси, — это сервер, который находится перед группой клиентских машин. Когда эти компьютеры делают запросы к сайтам и сервисам в интернете, прокси-сервер перехватывает эти запросы, а затем общается с веб-серверами от имени этих клиентов, как посредник.
	
	**Преимущества**
	Вот некоторые преимущества прямого прокси:
	*   Блокирует доступ к определенному контенту
	*   Позволяет доступ к гео-ограниченному контенту
	*   Обеспечивает анонимность
	*   Позволяет избежать других ограничений просмотра
	
	Хотя прокси обеспечивают преимущества анонимности, они все же могут отслеживать нашу личную информацию. Настройка и обслуживание прокси-сервера могут быть дорогостоящими и требуют конфигураций.

* **Обратный прокси (Reverse Proxy)**
	Обратный прокси — это сервер, который находится перед одним или несколькими веб-серверами, перехватывая запросы от клиентов. Когда клиенты отправляют запросы на сервер-источник веб-сайта, эти запросы перехватываются обратным прокси-сервером.
	
	Разница между прямым и обратным прокси subtle но важна. Упрощенно можно сказать, что прямой прокси находится перед клиентом и гарантирует, что ни один сервер-источник никогда не общается напрямую с этим конкретным клиентом. С другой стороны, обратный прокси находится перед сервером-источником и гарантирует, что ни один клиент никогда не общается напрямую с этим сервером-источником.
	
	Внедрение обратного прокси приводит к increased сложности. Один обратный прокси — это единая точка отказа, настройка нескольких обратных прокси (т.е. резервирование) further увеличивает сложность.
	
	**Преимущества**
	Вот некоторые преимущества использования обратного прокси:
	*   Улучшенная безопасность
	*   Кэширование
	*   SSL-шифрование
	*   Балансировка нагрузки
	*   Масштабируемость и гибкость

#### Балансировщик нагрузки против Обратного прокси

Подождите, разве обратный прокси не похож на балансировщик нагрузки? Что ж, нет, так как балансировщик нагрузки полезен, когда у нас несколько серверов. Часто балансировщики нагрузки маршрутизируют трафик на набор серверов, обслуживающих одну и ту же функцию, в то время как обратные прокси могут быть полезны даже только с одним веб-сервером или сервером приложений. Обратный прокси также может действовать как балансировщик нагрузки, но не наоборот.

#### Примеры

Ниже приведены некоторые commonly используемые прокси-технологии:
*   Nginx
*   HAProxy
*   Traefik
*   Envoy

---

### Доступность (Availability) ###

**Доступность** — это время, в течение которого система остается operational для выполнения своей требуемой функции в определенный период. Это простая мера процента времени, в течение которого система, служба или машина остается работоспособной в нормальных условиях.

#### Девятки доступности (The Nine's of availability)

Доступность часто количественно определяется временем бесперебойной работы (uptime) (или временем простоя - downtime) в процентах от времени, когда служба доступна. Обычно она измеряется в количестве «девяток».

| Доступность (Процент) | Время простоя (Год) | Время простоя (Месяц) | Время простоя (Неделя) |
| :--- | :--- | :--- | :--- |
| 90% (одна девятка) | 36.53 дней | 72 часа | 16.8 часов |
| 99% (две девятки) | 3.65 дней | 7.20 часов | 1.68 часов |
| 99.9% (три девятки) | 8.77 часов | 43.8 минут | 10.1 минут |
| 99.99% (четыре девятки) | 52.6 минут | 4.32 минут | 1.01 минут |
| 99.999% (пять девяток) | 5.25 минут | 25.9 секунд | 6.05 секунд |
| 99.9999% (шесть девяток) | 31.56 секунд | 2.59 секунд | 604.8 миллисекунд |
| 99.99999% (семь девяток) | 3.15 секунд | 263 миллисекунд | 60.5 миллисекунд |
| 99.999999% (восемь девяток) | 315.6 миллисекунд | 26.3 миллисекунд | 6 миллисекунд |
| 99.9999999% (девять девяток) | 31.6 миллисекунд | 2.6 миллисекунд | 0.6 миллисекунд |

#### Доступность последовательно vs параллельно

Если служба состоит из нескольких компонентов, подверженных сбоям, общая доступность службы зависит от того, соединены ли компоненты последовательно или параллельно.

* **Последовательно (Sequence)**
	Общая доступность уменьшается, когда два компонента соединены последовательно.
	==`Доступность (Общая) = Доступность (Foo) * Доступность (Bar)`==
	Например, если и Foo, и Bar имели доступность 99.9%, их общая доступность при последовательном соединении составила бы 99.8%.

* **Параллельно (Parallel)**
	Общая доступность увеличивается, когда два компонента соединены параллельно.
	==`Доступность (Общая) = 1 - (1 - Доступность (Foo)) * (1 - Доступность (Bar))`==
	Например, если и Foo, и Bar имели доступность 99.9%, их общая доступность при параллельном соединении составила бы 99.9999%.

#### Доступность против Надежности (Availability vs Reliability)

Если система надежна, она доступна. Однако, если она доступна, она не обязательно надежна. Другими словами, высокая надежность способствует высокой доступности, но можно достичь высокой доступности даже с ненадежной системой.

#### Высокая доступность против Отказоустойчивости (High availability vs Fault Tolerance)

И высокая доступность, и отказоустойчивость относятся к методам обеспечения высоких уровней времени бесперебойной работы. Однако они достигают цели по-разному.

Отказоустойчивая система не имеет перерывов в обслуживании, но имеет значительно более высокую стоимость, в то время как высокодоступная система имеет минимальный перерыв в обслуживании. Отказоустойчивость требует полной аппаратной избыточности, так как если основная система выходит из строя, без потери времени бесперебойной работы другая система должна взять на себя управление.

---

### Масштабируемость (Scalability) ###

**Масштабируемость** — это мера того, насколько хорошо система реагирует на изменения путем добавления или удаления ресурсов для удовлетворения спроса.

Давайте обсудим различные типы масштабирования:

* **Вертикальное масштабирование (Vertical scaling)**
	Вертикальное масштабирование (также известное как scaling up) расширяет масштабируемость системы путем добавления большей мощности к существующей машине. Другими словами, вертикальное масштабирование refers к улучшению возможностей приложения за счет увеличения аппаратной мощности.
	
	**Преимущества**
	*   Простота реализации
	*   Легче управлять
	*   Согласованность данных
	
	**Недостатки**
	*   Риск длительного простоя
	*   Сложнее обновлять
	*   Может быть единой точкой отказа

* **Горизонтальное масштабирование (Horizontal scaling)**
	Горизонтальное масштабирование (также известное как scaling out) расширяет масштаб системы путем добавления большего количества машин. Оно улучшает производительность сервера путем добавления большего количества экземпляров в существующий пул серверов, позволяя более равномерно распределять нагрузку.
	
	**Преимущества**
	*   Повышенная избыточность
	*   Лучшая отказоустойчивость
	*   Гибкость и эффективность
	*   Легче обновлять
	
	**Недостатки**
	*   Повышенная сложность
	*   Несогласованность данных
	*   Повышенная нагрузка на нисходящие сервисы (downstream services)

---

### Хранилище (Storage) ###

**Хранилище** — это механизм, который позволяет системе сохранять данные, либо временно, либо постоянно. Эту тему в основном пропускают в контексте системного проектирования, однако важно иметь базовое понимание некоторых common типов методов хранения, которые могут помочь нам точно настроить наши компоненты хранения. Давайте обсудим некоторые важные концепции хранения:

**RAID**
**RAID** (избыточный массив независимых дисков) — это способ хранения одних и тех же данных на нескольких жестких дисках или твердотельных накопителях (SSD) для защиты данных в случае сбоя диска.

Существуют разные уровни RAID, однако не все из них aimed на обеспечение избыточности. Давайте обсудим некоторые commonly используемые уровни RAID:

*   **RAID 0:** Также известен как чередование (striping), данные равномерно распределяются по всем дискам в массиве.
*   **RAID 1:** Также известен как зеркалирование (mirroring), по крайней мере два диска содержат точную копию набора данных. Если один диск выходит из строя, другие будут продолжать работать.
*   **RAID 5:** Чередование с четностью (Striping with parity). Требует использования как минимум 3 дисков, чередует данные по нескольким дискам, как RAID 0, но также имеет четность, распределенную по дискам.
*   **RAID 6:** Чередование с двойной четностью (Striping with double parity). RAID 6 похож на RAID 5, но данные четности записываются на два диска.
*   **RAID 10:** Объединяет чередование плюс зеркалирование из RAID 0 и RAID 1. Он обеспечивает безопасность, зеркалируя все данные на вторичных дисках, одновременно используя чередование по каждому набору дисков для ускорения передачи данных.

#### Сравнение

Давайте сравним все особенности различных уровней RAID:

| Особенности | RAID 0 | RAID 1 | RAID 5 | RAID 6 | RAID 10 |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **Описание** | Чередование | Зеркалирование | Чередование с четностью | Чередование с двойной четностью | Чередование и Зеркалирование |
| **Минимум дисков** | 2 | 2 | 3 | 4 | 4 |
| **Производительность чтения** | Высокая | Высокая | Высокая | Высокая | Высокая |
| **Производительность записи** | Высокая | Средняя | Высокая | Высокая | Средняя |
| **Стоимость** | Низкая | Высокая | Низкая | Низкая | Высокая |
| **Отказоустойчивость** | Нет | Одиночный сбой диска | Одиночный сбой диска | Двойной сбой диска | До одного сбоя диска в каждом подмассиве |
| **Использование емкости** | 100% | 50% | 67%-94% | 50%-80% | 50% |

#### Тома (Volumes)

**Том** — это фиксированный объем хранилища на диске или ленте. Термин «том» часто используется как синоним самого хранилища, но возможно, чтобы один диск содержал более одного тома или том spanned более чем на один диск.

#### Файловое хранилище (File storage)

**Файловое хранилище** — это решение для хранения данных в виде файлов и представления его конечным пользователям в виде иерархической структуры каталогов. Основное преимущество — предоставление удобного для пользователя решения для хранения и извлечения файлов. Чтобы найти файл в файловом хранилище, требуется полный путь к файлу. Оно экономично и легко структурировано и обычно находится на жестких дисках, что означает, что они выглядят точно так же для пользователя и на жестком диске.

*   **Пример:** Amazon EFS, Azure Files, Google Cloud Filestore и т.д.

#### Блочное хранилище (Block storage)

**Блочное хранилище** делит данные на блоки (chunks) и сохраняет их как отдельные части. Каждому блоку данных присваивается уникальный идентификатор, который позволяет системе хранения размещать меньшие фрагменты данных там, где это наиболее удобно.

Блочное хранилище также отделяет данные от пользовательских сред, позволяя распределять эти данные по нескольким средам. Это создает несколько путей к данным и позволяет пользователю быстро их извлекать. Когда пользователь или приложение запрашивает данные из системы блочного хранилища, нижележащая система хранения собирает блоки данных и представляет данные пользователю или приложению.

*   **Пример:** Amazon EBS.

#### Объектное хранилище (Object Storage)

**Объектное хранилище**, которое также известно как объектно-ориентированное хранилище, разбивает файлы данных на части, называемые объектами. Затем оно сохраняет эти объекты в едином репозитории, который может быть распределен по нескольким сетевым системам.

*   **Пример:** Amazon S3, Azure Blob Storage, Google Cloud Storage и т.д.

#### NAS (Network Attached Storage)

**NAS** (Сетевое хранилище) — это устройство хранения данных, подключенное к сети, которое позволяет хранить и извлекать данные из центрального местоположения для авторизованных сетевых пользователей. Устройства NAS гибки, то есть по мере необходимости в дополнительном хранилище мы можем добавить к тому, что у нас есть. Это быстрее, дешевле и предоставляет все преимущества публичного облака на месте, давая нам полный контроль.

#### HDFS (Hadoop Distributed File System)

**Hadoop Distributed File System (HDFS)** — это распределенная файловая система, предназначенная для работы на стандартном оборудовании. HDFS обладает высокой отказоустойчивостью и предназначена для развертывания на недорогом оборудовании. HDFS обеспечивает высокую пропускную способность доступа к данным приложений и подходит для приложений, которые имеют большие наборы данных. Она имеет много общего с существующими распределенными файловыми системами.

HDFS предназначена для надежного хранения очень больших файлов на машинах в большом кластере. Она хранит каждый файл в виде последовательности блоков; все блоки в файле, кроме последнего, имеют одинаковый размер. Блоки файла реплицируются для отказоустойчивости.